---
title: Cows and Sunshine
author: "Sidharth Gupta"
date: \today
output:
   html_document:
    css: css/code.css
    highlight: default
    citation_package:
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
runtime: shiny
fontsize: 11pt
geometry: margin=1ine
header-includes:
- \usepackage{indentfirst}
- \usepackage{graphicx}
- \usepackage{geometry}
- \usepackage{subfigure}
- \usepackage{amsmath}
- \usepackage{listings}
- \usepackage{tikz}
- \usetikzlibrary{matrix}
---

```{r setUp, tidy = TRUE, message = FALSE, warning = FALSE, error = FALSE}
library(rstan)
library(dplyr)
library(magrittr)
library(gridExtra)
library(ggplot2)
library(bayesplot)
library(reshape2)
```
## Question 9
Farmer Jöns has a huge number of cows. He is wondering whether the amount of time a cow spends outside in the sunshine affects how much milk she produces. To test this he makes a controlled experiment where he picks out 20 cows and assigns each a number of hours she should spend outside each day. The experiment runs for a month and Jöns records the number of liters of milk each cow produces. Copy-n-paste the following into R and inspect the resulting data frame d.
```{r}
d <- data.frame(milk = c(685, 691, 476, 1151, 879, 725, 1190, 1107, 809, 539,
                         298, 805, 820, 498, 1026, 1217, 1177, 684, 1061, 834),
                hours = c(3, 7, 6, 10, 6, 5, 10, 11, 9, 3, 6, 6, 3, 5, 8, 11, 
                          12, 9, 5, 5))
```
Using this data on hours of sunshine and resulting liters of milk Jöns wants to know: Does sunshine affect milk production positively or negatively?

Lets look at the plot of the raw data. 
```{r}
ggplot(d, aes(x=hours, y = milk)) + geom_point() + 
    geom_smooth(method='lm') +
    geom_smooth(method='loess', color='red')
```

Remember that the localized regression smoother shows that the relationship is not very linear. 

Assuming that farmer jon has controlled for all other factors experimentally like diet, without sun production etc there seems some positive association between hours in the sun and milk production.
We should center the X's, this will help us interpret the coefficients in terms of milk change per sunshine hour. It will also help us interpret the intercept as the expected value of Y in the linear model. If we center Y as well then then intercept term will be zero.
```{r stan, tidy = TRUE, message = FALSE, warning = FALSE, error = FALSE, cache=TRUE, results='hide', echo=FALSE}
set.seed(100)
fit.stan = stan(
                "./cows_and_sun.stan", 
                data=list(y= d$milk, N = nrow(d), x=d$hours), 
                iter=5000, chains=4, cores=4, control=list(adapt_delta=0.99))

```

1. I tried centering just the X's and that seemed to produce divergent
   transactions. I had very tight priors on the slope and the beta was almost
   zero:
```{r eval=FALSE}

target += uniform_lpdf(sigma|0,1000);
target += uniform_lpdf(a|-1000, 1000);
target += normal_lpdf(b|0, 1);

         mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff
a      832.47    0.81 63.37  701.61  791.86  834.03  874.82  955.09  6152
b        0.05    0.01  1.00   -1.93   -0.63    0.05    0.72    2.03  7445
sigma  285.78    0.68 51.44  206.54  249.59  278.74  314.35  405.21  5678
lp__  -150.97    0.02  1.23 -154.16 -151.56 -150.67 -150.06 -149.54  3493
```

2. Of course the slope was ~ 0. The unit change in X will still cause large
   changes in Y because the Y's are not centered, so the prior needs to be much
   looser. I need to center Y as well:

```{r eval=FALSE}
target += uniform_lpdf(sigma|0,1000); 
target += uniform_lpdf(a|-1000, 1000);
target += normal_lpdf(b|0, 100);

         mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff
a      833.81    0.61 49.64  735.92  801.06  833.42  866.73  932.94  6627
b      137.17    0.58 46.44   41.03  107.84  138.86  168.32  225.47  6421
sigma  224.76    0.57 41.30  160.50  195.20  219.49  247.95  320.67  5321
lp__  -151.57    0.02  1.25 -154.79 -152.16 -151.25 -150.65 -150.14  3360
```

3. Once we standardize both the variables the regression line is in agreement
   with the linear model from earlier. And we can see that the uncertainity is
   still pretty large.

```{r eval=FALSE}
        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
a       0.00    0.00 0.18  -0.36  -0.12   0.00   0.12   0.35  6807    1
b       0.63    0.00 0.19   0.25   0.51   0.63   0.75   0.99  6855    1
sigma   0.82    0.00 0.14   0.59   0.72   0.80   0.90   1.14  5639    1
lp__  -27.47    0.02 1.29 -30.77 -28.06 -27.15 -26.52 -25.98  3255    1
```


```{r ppc, tidy = TRUE, message = FALSE, warning = FALSE, error = FALSE }
sims = data.frame(as.matrix(fit.stan))
coefs = sims %>% dplyr::select(a,b) %>% as.matrix()

set.seed(1000)
p1 = ggplot(data=d, aes(x=(hours-mean(hours))/sd(hours), y=(milk-mean(milk))/sd(milk))) + geom_point(color='red')
p1 =  p1+ geom_abline(data=sims %>% dplyr::sample_n(100), aes(slope=b, intercept=a), alpha=0.1) 
print(p1)

p1 = ggplot(sims %>% select(a, b) %>% melt, aes(x=value, color=variable)) + geom_density()
p2 = ggplot(sims %>% select(a, b, sigma) %>% melt, aes(x=variable, y=value, color=variable)) + 
    stat_summary(fun.y=mean, 
                 fun.ymax = function(x) {quantile(x, 0.95)},
                 fun.ymin = function(x) {quantile(x, 0.05)},
                 geom="pointrange")
grid.arrange(p1, p2, ncol=2)
```

There are more ideas we can try with the Stan program to improve its efficiency by using for example cholesky decomposition, but that is in more useful in hierarchical models.
